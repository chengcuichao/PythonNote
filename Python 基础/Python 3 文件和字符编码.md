### 文件

#### 打开文件模式

```python
'''
"r"只读模式（默认）。
   w，只写模式，不可读，不存在则创建；存在则删除内容
   a，追加模式，可读，不存在则创建；存在则只追加内容
   x, 写模式，当文件系统上不存在，才可以写。也就是不允许覆盖已存在的文件内容

"+"表示可以同时读写某个文件：
   r+，可读写文件。可读；可写；可追加
   w+，写读
   a+，同a

"U"表示在读取时，可以将 \r \n \r\n自动转换成\n（与r或r+ 模式同使用）：
   rU
   r+U

"b"表示处理二进制文件（如：FTP发送上传ISO镜像文件，linux可忽略，windows处理二进制文件时需标注）：
   rb
   wb
   ab
   xb   
'''
```

修改文件

```python
f = open("password","r",encoding="utf-8")
f.bak = open("password.bak","w",encoding="utf-8")
for line in f:
   if "#打印文件" in line:
       line =  line.replace("#打印文件","eeeeeeee")
   f.bak.write(line)
f.close()
```

小例子

```python
#使用print将字符串写进文件里
with open('d:/work/test.txt','wt') as f:
    print('Hello World!',file=f)

#格式化打印
print('ACME',50,91.5, sep=',', end='!!\n')
>>>ACME,50,91.5!!
```

#### 文件的方法

```python
file.next()　			   #返回文件下一行
file.read([size]) 			#从文件读取指定的字节数，如果未给定或为负则读取所有。
file.readline([size]) 		#读取整行，包括 "\n" 字符。
file.write(str) 			#将字符串写入文件，没有返回值。
file.writelines(sequence) 	#向文件写入一个序列字符串列表，如果需要换行则要自己加入每行的换行符。
file.seek(offset[, whence])	#设置文件当前位置
file.tell()					#返回文件当前位置
file.truncate([size])		#截取文件，截取的字节通过size指定，默认为当前文件位置。
file.readinto() 			#读取数据到一个可变缓冲区中
file.close()　			   #关闭文件，关闭后文件不能再进行读写操作

#刷新文件内部缓冲，直接把内部缓冲区的数据立刻写入文件, 而不是被动的等待输出缓冲区写入
file.flush()

#返回一个整型的文件描述符(file descriptor FD 整型), 可以用在如os模块的read方法等一些底层操作上
file.fileno()

#如果文件连接到一个终端设备返回 True，否则返回 False
file.isatty()

#读取所有行并返回列表，若给定sizeint>0，返回总和大约为sizeint字节的行, 实际读取值可能比 sizeint 较大, 因为需要填充缓冲区。
file.readlines([sizeint])
```

#### 读写压缩文件

```python
# gzip和bz2模块可以很容易的处理这些文件
import gzip,bz2

with gzip.open('12.gz','rt') as f:
    print(f.readline())

with bz2.open('12.bz2','rt') as f:
    print(f.readline())

# 当写入压缩数据时，可以使用compresslevel这个可选的关键字参数来指定一个压缩级别,默认的等级是9，也是最高的压缩等级。等级越低性能越好，但是数据压缩程度也越低。
with gzip.open('somefile.gz','wt', compresslevel=5) as f:
    f.write('text')

# gzip.open()和bz2.open()还有一个很少被知道的特性，它们可以作用在一个已存在并以二进制模式打开的文件上。
import gzip

f = open('somefile.gz','rb')
with gzip.open(f,'rt') as g:
    text=g.read()

# 这样就允许gzip和bz2模块可以工作在许多类文件对象上，比如套接字，管道和内存中文件等。
```

### 字符编码

完全理解字符编码 与 Python 的渊源前，我们有必要把一些基础概念弄清楚，虽然有些概念我们每天都在接触甚至在使用它，但并不一定真正理解它。比如：字节、字符、字符集、字符码、字符编码。

#### 字节

字节（Byte）是计算机中数据存储的基本单元，一字节等于一个8位的比特，计算机中的所有数据，不论是保存在磁盘文件上的还是网络上传输的数据（文字、图片、视频、音频文件）都是由字节组成的。

#### 字符

你正在阅读的这篇文章就是由很多个字符（Character）构成的，字符一个信息单位，它是各种文字和符号的统称，比如一个英文字母是一个字符，一个汉字是一个字符，一个标点符号也是一个字符。

#### 字符集

字符集（Character Set）就是某个范围内字符的集合，不同的字符集规定了字符的个数，比如 ASCII 字符集总共有128个字符，包含了英文字母、阿拉伯数字、标点符号和控制符。而 GB2312 字符集定义了7445个字符，包含了绝大部分汉字字符。

#### 字符码

字符码（Code Point）指的是字符集中每个字符的数字编号，例如 ASCII 字符集用 0-127 连续的128个数字分别表示128个字符，例如 "A" 的字符码编号就是65。

#### 字符编码

字符编码（Character Encoding）是将字符集中的字符码映射为字节流的一种具体实现方案，常见的字符编码有 ASCII 编码、UTF-8 编码、GBK 编码等。某种意义上来说，字符集与字符编码有种对应关系，例如 ASCII 字符集对应 有 ASCII 编码。ASCII 字符编码规定使用单字节中低位的7个比特去编码所有的字符。例如"A" 的编号是65，用单字节表示就是0×41，因此写入存储设备的时候就是b'01000001'。

#### ASCII 码

说到字符编码，要从计算机的诞生开始讲起，计算机发明于美国，在英语世界里，常用字符非常有限，26个字母（大小写）、10个数字、标点符号、控制符，这些字符在计算机中用一个字节的存储空间来表示绰绰有余，因为一个字节相当于8个比特位，8个比特位可以表示256个符号。于是美国国家标准协会ANSI制定了一套字符编码的标准叫 ASCII(American Standard Code for Information Interchange)，每个字符都对应唯一的一个数字，比如字符 "A" 对应数字是65，"B" 对应 66，以此类推。最早 ASCII 只定义了128个字符编码，包括96个文字和32个控制符号，一共128个字符只需要一个字节的7位就能表示所有的字符，因此 ASCII 只使用了一个字节的后7位，剩下最高位1比特被用作一些通讯系统的奇偶校验。

#### 扩展的 ASCII，EASCII(ISO/8859-1)

　　然而计算机慢慢地普及到其他西欧地区时，发现还有很多西欧字符是 ASCII 字符集中没有的，显然 ASCII 已经没法满足人们的需求了，好在 ASCII 字符只用了字节的7位 0×00~0x7F 共128个字符，于是他们在 ASCII 的基础上把原来的7位扩充到8位，把0×80-0xFF这后面的128个数字利用起来，叫 EASCII ，它完全兼容ASCII，扩展出来的符号包括表格符号、计算符号、希腊字母和特殊的拉丁符号。然而 EASCII 时代是一个混乱的时代，各个厂家都有自己的想法，大家没有统一标准，他们各自把最高位按照自己的标准实现了自己的一套字符编码标准，比较著名的就有 CP437 ， CP437 是 始祖IBM PC、MS-DOS使用的字符编码。众多的 ASCII 扩充字符集之间互不兼容，这样导致人们无法正常交流，例如200在CP437字符集表示的字符是 È ，在 ISO/8859-1 字符集里面显示的就是 ╚，于是国际标准化组织（ISO）及国际电工委员会（IEC）联合制定的一系列8位字符集的标准 ISO/8859-1(Latin-1) ，它继承了 CP437 字符编码的128-159之间的字符，所以它是从160开始定义的，ISO-8859-1在 CP437 的基础上重新定义了 160~255之间的字符。

#### 多字节字符编码 GBK

ASCII 字符编码是单字节编码，计算机进入中国后面临的一个问题是如何处理汉字，对于拉丁语系国家来说通过扩展最高位，单字节表示所有的字符已经绰绰有余，但是对于亚洲国家来说一个字节就显得捉襟见肘了。于是中国人自己弄了一套叫 GB2312 的双字节字符编码，又称GB0，1981 由中国国家标准总局发布。GB2312 编码共收录了6763个汉字，同时他还兼容 ASCII，GB 2312的出现，基本满足了汉字的计算机处理需要，它所收录的汉字已经覆盖中国大陆99.75%的使用频率，不过 GB2312 还是不能100%满足中国汉字的需求，对一些罕见的字和繁体字 GB2312 没法处理，后来就在GB2312的基础上创建了一种叫 GBK 的编码，GBK 不仅收录了27484个汉字，同时还收录了藏文、蒙文、维吾尔文等主要的少数民族文字。同样 GBK 也是兼容 ASCII 编码的，对于英文字符用1个字节来表示，汉字用两个字节来标识。

#### Unicode 的问世

GBK仅仅只是解决了我们自己的问题，但是计算机不止是美国人和中国人用啊，还有欧洲、亚洲其他国家的文字诸如日文、韩文全世界各地的文字加起来估计也有好几十万，这已经大大超出了ASCII 码甚至GBK 所能表示的范围了，虽然各个国家可以制定自己的编码方案，但是数据在不同国家传输就会出现各种各样的乱码问题。如果只用一种字符编码就能表示地球甚至火星上任何一个字符时，问题就迎刃而解了。是它，是它，就是它，我们的小英雄，统一联盟国际组织提出了Unicode 编码，Unicode 的学名是"Universal Multiple-Octet Coded Character Set"，简称为UCS。它为世界上每一种语言的每一个字符定义了一个唯一的字符码，Unicode 标准使用十六进制数字表示，数字前面加上前缀 U+，比如字母『A』的Unicode编码是 U+0041，汉字『中』的Unicode 编码是U+4E2D

Unicode有两种格式：UCS-2和UCS-4。UCS-2就是用两个字节编码，一共16个比特位，这样理论上最多可以表示65536个字符，不过要表示全世界所有的字符显示65536个数字还远远不过，因为光汉字就有近10万个，因此Unicode4.0规范定义了一组附加的字符编码，UCS-4就是用4个字节（实际上只用了31位，最高位必须为0）。理论上完全可以涵盖一切语言所用的符号。

#### Unicode 的局限

但是 Unicode 有一定的局限性，一个 Unicode 字符在网络上传输或者最终存储起来的时候，并不见得每个字符都需要两个字节，比如字符“A“，用一个字节就可以表示的字符，偏偏还要用两个字节，显然太浪费空间了。

　　第二问题是，一个 Unicode 字符保存到计算机里面时就是一串01数字，那么计算机怎么知道一个2字节的Unicode字符是表示一个2字节的字符呢，例如“汉”字的 Unicode 编码是 U+6C49，我可以用4个ascii数字来传输、保存这个字符；也可以用utf-8编码的3个连续的字节E6 B1 89来表示它。关键在于通信双方都要认可。因此Unicode编码有不同的实现方式，比如：UTF-8、UTF-16等等。Unicode就像英语一样，做为国与国之间交流世界通用的标准，每个国家有自己的语言，他们把标准的英文文档翻译成自己国家的文字，这是实现方式，就像utf-8。

#### UTF-8 具体实现

UTF-8（Unicode Transformation Format）作为 Unicode 的一种实现方式，广泛应用于互联网，它是一种变长的字符编码，可以根据具体情况用1-4个字节来表示一个字符。比如英文字符这些原本就可以用 ASCII 码表示的字符用UTF-8表示时就只需要一个字节的空间，和 ASCII 是一样的。对于多字节（n个字节）的字符，第一个字节的前n为都设为1，第n+1位设为0，后面字节的前两位都设为10。剩下的二进制位全部用该字符的unicode码填充。以『好』为例，『好』对应的 Unicode 是597D，对应的区间是 0000 0800--0000 FFFF，因此它用 UTF-8 表示时需要用3个字节来存储，597D用二进制表示是： 0101100101111101，填充到 1110xxxx 10xxxxxx 10xxxxxx 得到 11100101 10100101 10111101，转换成16进制是 e5a5bd，因此『好』的 Unicode 码 U+597D 对应的 UTF-8 编码是 "E5A5BD"。

#### 编码和解码的含义

　　**编码的过程是将字符转换成字节流，解码的过程是将字节流解析为字符。**

### Python3 的编码、解码

#### 含义

**1、字符加载进内存的编码格式是Unicode。**

**2、编码是用指定的字符集将字符转换为字节流。**

**3、解码是用指定的字符集将字节流转化为字符。**

#### 说明

Python3 也有两种数据类型，str和bytes，str类型存unicode数据，bytes类型存bytes数据。

**1、当打开文件时，需要指定字符集来确定用什么字符集来将bytes解码成unicode数据。**

**2、保存文件时，也需要指定字符集来确定将unicode的数据编码为bytes类型数据。**



